# Application: Data Engineer @ J2 Health

**Generated:** 2026-02-20
**Candidate:** James Patrick Mayo
**Overall Fit Score:** 8/10
**Competition-Adjusted Score:** 8.25/10
**Recommendation:** APPLY (highest priority — freshest posting, lowest competition)
**Threshold:** 7.5/10 required for full application generation. Resume and cover letter included below.
**Source:** https://boards.greenhouse.io/j2health/jobs/5112516008
**LinkedIn:** No LinkedIn listing found. J2 Health posts exclusively via Greenhouse and VC boards (Primary Venture Partners). Apply via Greenhouse link above.

---

# PART 1: FIT EVALUATION

## Job Analysis

| Field | Details |
|---|---|
| **Company** | J2 Health — Healthcare tech, provider network design and management. Combines best-in-class data with purpose-built software. Backed by Tiger Global and Primary Ventures. Early-stage. |
| **Title** | Data Engineer |
| **Seniority Level** | Mid (3-5 years required), but first Data Engineer hire — requires senior-level autonomy and process ownership |
| **Location & Work Model** | New York, NY — 3 days/week in-office; remote possible for exceptional candidates |
| **Salary Range** | $150,000 – $175,000/yr + equity + benefits |
| **Core Function** | Build and optimize production-grade data pipelines. Design scalable data infrastructure. Improve data observability, quality, and integrity. First data engineering hire — build the function from scratch. |

**Required Skills:**
1. 3-5 years data engineering experience
2. Python engineering practices + opinions on LLM coding tools
3. SQL
4. dbt experience
5. Familiarity with orchestration tools (Dagster, Airflow)
6. Batch processing of large data
7. Production experience with columnar data warehouses and transactional databases
8. Small, cross-functional team experience

**Preferred Skills:**
- Data observability and testing capabilities
- High-scale ingestion pipeline architecture
- Customer reporting workflow productization

**Soft Skill Signals:**
- Autonomous, self-directed (first hire in function)
- Collaborative across data science, analytics, and software engineering
- Opinionated on tooling choices (LLM tools explicitly asked about)

**Domain Context:**
- Healthcare provider networks — but the data engineering work itself is domain-agnostic (pipelines, warehousing, quality)

**Key Keywords:**
dbt, Python, SQL, data pipelines, data observability, data quality, batch processing, columnar warehouse, orchestration, Dagster, Airflow, cross-functional, LLM coding tools

---

## Skill Match Matrix

### Required Skills

| Requirement | Match | Candidate Skill | Proficiency | Evidence |
|---|---|---|---|---|
| 3-5 years data engineering experience | **STRONG MATCH** | Data Engineering (pipeline design, modeling, quality) | expert / advanced | 7+ years total technical experience; 5+ years directly in data engineering. dbt, ELT pipelines, data quality at both QuotaPath and Success Academy. Exceeds the 3-5yr requirement. |
| Python engineering practices | **STRONG MATCH** | Python | advanced (4yr) | Built production transformation pipelines at QuotaPath using Dask/Pandas, reducing runtimes from hours to minutes. Standardized Jupyter Notebooks for testing against production data. Lambda test scripts at Success Academy. |
| Opinions on LLM coding tools | **STRONG MATCH** | AI-Assisted Development | advanced (2yr) | Daily user of Cursor, ChatGPT, and Claude for modeling, documentation, workflow scaffolding, and schema generation. Built AI-assisted scoping workflows at QuotaPath. |
| SQL | **STRONG MATCH** | SQL | expert (7yr) | Primary language across all roles. 1,900+ dbt models, complex CTEs/window functions, TB-scale queries, data validation frameworks. |
| dbt experience | **STRONG MATCH** | dbt Cloud | expert (3yr) | 1,900+ production models at Success Academy. Tests, macros, documentation at scale. Modular Medallion-aligned models at QuotaPath. This is a standout match. |
| Orchestration tools (Dagster, Airflow) | **PARTIAL MATCH** | Pipeline Orchestration | intermediate (2yr) | Airflow exposure at QuotaPath. CircleCI/Prefect orchestration workflows at QuotaPath. Step Functions-based workflows at Success Academy. Jenkins CI jobs at Cision. No Dagster experience specifically. |
| Batch processing of large data | **STRONG MATCH** | ELT/ETL Design, Data Modeling | advanced | TB-scale dataset processing at both QuotaPath and Success Academy. Migrated row-by-row SQL to parallelized Python (Dask) batch transforms. 90+ ETL pipelines. |
| Columnar warehouses + transactional DBs | **STRONG MATCH** | Snowflake, Redshift, PostgreSQL | intermediate-advanced | Snowflake at QuotaPath (1yr), Redshift at Success Academy (2yr) — both columnar. PostgreSQL (4yr, advanced) as transactional DB across multiple roles. |
| Small cross-functional team | **STRONG MATCH** | Cross-Functional Collaboration | advanced | QuotaPath was a startup (51-200 employees). Partnered with Product, Engineering, Customer Success. Led cross-functional delivery at Success Academy with Engineering, Analytics, Operations. |

### Preferred Skills

| Requirement | Match | Evidence |
|---|---|---|
| Data observability and testing | **STRONG MATCH** | Created QA function from scratch at Success Academy. Built data validation frameworks at QuotaPath. Freshness, validity, schema tests across 90+ pipelines and 150+ dashboards. |
| High-scale ingestion pipelines | **STRONG MATCH** | TB-scale data processing. 90+ ETL pipelines. AWS Lambda-based ingestion support. Airbyte data integration at QuotaPath. |
| Customer reporting productization | **PARTIAL MATCH** | Supported 150+ dashboards, led Sisense-to-Looker migration, built automated reports. Not directly productizing into application features, but adjacent experience. |

---

## Experience Relevance

| Role | Relevance | Reasoning | Best Bullets |
|---|---|---|---|
| **Solutions Engineer / Data Platform Architect @ QuotaPath** | **HIGH** | Designed ELT pipelines into Snowflake, built dbt models with Medallion architecture, Python batch transforms (Dask/Pandas), data validation frameworks, CI/CD pipelines. Small startup team. LLM tool usage. | ELT pipeline design; Python transforms reducing hours to minutes; data validation frameworks; CI/CD automation (70-90%); dbt Medallion models; TB-scale processing |
| **Data Quality Analyst / Analytics Engineer @ Success Academy** | **HIGH** | Built data quality function from scratch — exactly the "first hire" narrative J2 needs. 1,900+ dbt models, TB-scale, Medallion architecture, AWS infrastructure, automated testing. Cross-functional delivery. | Created QA process from scratch; 1,900+ dbt models; data quality checks at scale; multi-phase migrations; AWS Lambda/Step Functions; 2 direct reports |
| **Production Engineer @ Cision** | **MEDIUM** | Production data analysis across PostgreSQL, Cassandra, ElasticSearch. Root cause analysis, bug triage. Shows database breadth and production debugging skills. | 300+ bug investigations across multiple database systems; Jupyter Notebook scripts for data integrity |
| **Data Quality Analyst @ Cision** | **LOW-MEDIUM** | Jenkins jobs for data integrity, GDPR compliance across ingestion pipelines. Some relevant pipeline monitoring experience but less directly applicable. | Jenkins automation jobs; GDPR compliance; data integrity scripts |

---

## LinkedIn Verification

| Field | Details |
|---|---|
| **LinkedIn URL** | Not found as direct LinkedIn listing — posted via Greenhouse and Primary Venture Partners job board |
| **Posting Age** | ~1-2 weeks (posted Feb 7 per Primary VC board) |
| **Applicant Count** | Estimated <50 — small company (11-50 employees), first DE hire, niche healthcare startup |
| **Source** | Jobright.ai ("1 week ago"), Primary Venture Partners board (Feb 7, 2026) |

---

## Overall Fit Score

| Category | Score | Reasoning |
|---|---|---|
| **Technical Skills Fit** | **9/10** | Near-perfect alignment on core stack: dbt (expert, 1,900+ models), Python (advanced, production transforms), SQL (expert, 7yr), columnar warehouses (Snowflake + Redshift), PostgreSQL, data quality automation. Only gap is Dagster specifically. |
| **Domain Experience Fit** | **4/10** | No healthcare data experience. However, the JD describes domain-agnostic data engineering work (pipelines, warehousing, quality, observability). Healthcare knowledge is not listed as a requirement. |
| **Soft Skills & Culture Fit** | **9/10** | Thrives building from scratch (created QA function at Success Academy, built processes at QuotaPath). Strong cross-functional collaboration. Active LLM tool user with informed opinions. Eagle Scout. Small-team experience. |
| **Seniority Fit** | **8/10** | JD asks for 3-5 years; James has 7+. Over-qualified on paper, but first-hire roles need that extra experience. Has managed direct reports, led architecture decisions, and built functions from zero — all critical for a solo data engineer. |
| **Overall Fit Score** | **8/10** | Exceptionally strong technical match, especially the dbt expertise and "build from scratch" narrative. The healthcare domain gap is minor since the work is infrastructure-focused. The Dagster gap is easily bridgeable. This is one of the strongest fits in James's current search. |
| **Recency Modifier** | **0** | 1-2 weeks old — normal timing, still within initial review window |
| **Competition Modifier** | **+0.25** | Estimated <50 applicants — small startup, first DE hire, niche role |
| **Competition-Adjusted Score** | **8.25/10** | Highest priority application. Fresh posting + low competition + strong fit = best odds in the batch. |
| **Interview Success Probability** | **55-70%** | Strong likelihood of passing initial screen — dbt expertise alone is a differentiator. Technical screen should go well on SQL, Python, dbt, and data quality topics. May be probed on Dagster and healthcare data specifics. System design discussions around pipeline architecture should be a strength. |

---

## Gap Analysis

| Gap | Severity | Mitigation |
|---|---|---|
| **Healthcare data domain** | **MINOR** | The JD does not list healthcare domain knowledge as a requirement. The data engineering work (pipelines, quality, observability) is domain-agnostic. James's experience across SaaS, education (51+ schools, 18K users), and enterprise data transfers directly. Mention eagerness to learn the domain in cover letter. |
| **Dagster specifically** | **MINOR** | Listed alongside Airflow as "familiarity with orchestration tools like Dagster and Airflow." James has Airflow exposure, CircleCI/Prefect production experience, and Step Functions familiarity. Orchestration concepts transfer directly. Dagster's Python-native approach aligns well with James's Python skills — ramp time is weeks. |
| **First dedicated DE hire expectations** | **MINOR** | This could mean wearing many hats and handling infrastructure work beyond just pipelines. James has demonstrated this breadth at QuotaPath (solutions + platform architecture) and Success Academy (QA + analytics engineering + migrations). This is actually a strength, not a gap. |

---

## Positioning Strategy

**Lead Narrative:**
"Data engineer who builds data functions from scratch — created a QA/data quality practice from zero at Success Academy, scaling to 1,900+ dbt models across TB-scale data, and now brings that same foundational energy to pipeline design, data quality, and observability."

**Roles to Emphasize:**
1. **Success Academy** — "Built from scratch" narrative, 1,900+ dbt models, data quality automation, TB-scale, Medallion architecture, AWS
2. **QuotaPath** — ELT pipelines, Snowflake, Python transforms (Dask/Pandas), data validation frameworks, CI/CD, LLM tools
3. **Cision** — PostgreSQL production experience, data integrity monitoring, breadth of database systems

**Skills to Highlight:**
1. dbt (expert — 1,900+ models, 3 years)
2. SQL (expert — 7 years)
3. Python (advanced — Dask/Pandas production transforms)
4. Data quality and observability (built frameworks from scratch)
5. Snowflake + Redshift (columnar warehouse experience)
6. Batch processing at TB scale
7. CI/CD and orchestration (CircleCI, Prefect, Airflow, GitHub Actions)
8. AI-assisted development (Cursor, ChatGPT, Claude)

**Skills to De-emphasize:**
- CRM integrations (Salesforce, HubSpot) — too solutions-engineer-specific
- Zapier, Power Query — not relevant to data engineering
- Client-facing work — downplay external customer focus, emphasize internal cross-functional
- BI tooling details (Looker, Sisense) — mention only through migration bullet

**Reframing Suggestions:**
- "Engineered and delivered tailored solutions for 300+ client onboarding projects" → Focus on the pipeline design and data validation aspects, not client count
- "Created the QA process from scratch" → "Built the data quality engineering function from zero, defining testing standards, automated monitoring, and observability practices"
- "Participated in Step Functions-based orchestration workflows" → Include naturally alongside other orchestration experience to strengthen the orchestration narrative

---

## Red Flags

### JD Red Flags
- **First Data Engineer hire** — Could mean unclear expectations, no peer review, and pressure to deliver across too wide a scope. Also an opportunity for high impact and ownership.
- **"Productizing customer reporting workflows into J2 application features"** — This edges into software engineering territory. May require building data features in the product, not just pipeline work. Worth clarifying scope in interview.
- **3 days/week in-office** — Noted "remote possible for exceptional candidates" which suggests flexibility but default expectation is hybrid.

### Candidate Red Flags
- **No healthcare data experience** — If the interviewer values domain knowledge (HIPAA, claims data, provider credentialing), this could surface. Prepare talking points about rapid domain ramp-up.
- **Title history doesn't say "Data Engineer"** — James's titles have been "Data Quality Analyst," "Analytics Engineer," "Solutions Engineer." May need to proactively frame the data engineering thread that runs through all roles.
- **Dagster unfamiliarity** — If the team is deeply invested in Dagster, questions about it could expose the gap. Study Dagster basics before interview.

---

## Application Recommendation

**Recommendation: APPLY**

**Reasoning:**
This is an exceptionally strong technical fit. The dbt expertise (1,900+ models, expert-level) is a standout differentiator — most candidates won't match that depth. The "first data engineer hire" framing maps perfectly to James's demonstrated ability to build functions from scratch at Success Academy. Python, SQL, data quality, columnar warehouses, batch processing, and LLM tools all align directly. The gaps (Dagster, healthcare domain) are minor and easily addressed. The salary range ($150-175k) is competitive. J2 Health's early stage and small team mirror environments where James has thrived.

**If Applying:**
- Lead with the "built from scratch" narrative — this is the single strongest selling point for a first DE hire
- Emphasize dbt expertise with specific scale (1,900+ models)
- Highlight data quality and observability experience — the JD explicitly defines success by these
- Mention LLM tool usage proactively — they specifically ask for opinions on this
- Address healthcare domain gap briefly in cover letter — frame as infrastructure-focused transferability
- Study Dagster basics before interview (Python-native, asset-based, software-defined assets)
- Research J2 Health's data stack if possible before interview

---

---

# PART 2: RESUME

JAMES PATRICK MAYO
New York, NY | mayojames409@gmail.com | linkedin.com/in/james-mayo-3ab3a1bb


SUMMARY

Autonomous, self-directed Data Engineer with 7+ years of experience designing scalable data infrastructure, building and optimizing production-grade data pipelines, and improving data quality and observability from the ground up. Expert in dbt (1,900+ production models), Python, and SQL across production data warehouses (Snowflake, Redshift) at TB scale. Collaborative builder with a proven track record creating data engineering functions from scratch in small, cross-functional teams, with strong opinions on LLM-assisted development workflows.


TECHNICAL SKILLS

Data Engineering: dbt Cloud (3yr, 1,900+ models), Medallion Architecture, Production-Grade Pipeline Design, Data Quality and Observability, Batch Processing, Data Modeling, Metadata and Lineage Documentation
Languages: SQL (7yr, expert), Python (4yr, Dask/Pandas, production batch transforms)
Orchestration and CI/CD: CircleCI/Prefect, Airflow, GitHub Actions, Jenkins, Automated Testing Frameworks
Cloud and Infrastructure: AWS (Lambda, Step Functions, RDS, Redshift), Snowflake, BigQuery/Google Cloud, Git
Databases: Snowflake, Redshift, PostgreSQL, Cassandra, ElasticSearch
Tools: Airbyte, Jupyter Notebooks, DBeaver, Jira/Confluence, Cursor/ChatGPT/Claude (AI-assisted development)


EXPERIENCE

Solutions Engineer / Data Platform Architect -- QuotaPath
Aug 2024 - Sep 2025 | Remote

Designed scalable data infrastructure and built production-grade data pipelines integrating CRM and financial system data into Snowflake, processing TB-scale datasets across 10+ enterprise data sources
Built modular dbt models aligned to Medallion architecture across production data warehouses with automated testing and comprehensive documentation
Optimized production-grade data pipelines by migrating batch processing of large datasets from row-by-row SQL to Python-based transformations (Dask/Pandas), reducing runtimes from hours to minutes
Created SQL-based data validation frameworks to improve data quality and data integrity, enforcing schema consistency and ingestion reliability, reducing data incidents by 50%+
Implemented CI/CD pipelines via GitHub Actions achieving 70-90% deployment automation with version control and automated testing
Accelerated development using Cursor, ChatGPT, and Claude for modeling, documentation scaffolding, and workflow automation

Data Quality Analyst / Analytics Engineer -- Success Academy Charter Schools
Feb 2022 - Jun 2024 | New York, NY

Self-directed creation of the data quality engineering function from scratch after rapid promotion, defining testing standards and automated monitoring to improve data observability across 51+ schools and 18,000+ users
Built and maintained 1,900+ dbt models including tests, macros, and documentation across production data warehouses (Redshift) in a Medallion architecture
Implemented automated data quality checks (freshness, validity, schema tests) to improve data quality and data integrity across 90+ production-grade data pipelines and 150+ dashboards at TB scale
Led multi-phase system migrations (Matillion to Talend to dbt; Sisense to Looker), architecting migration plans and validation criteria
Supported AWS Lambda-based batch processing of large data ingestion workloads and participated in Step Functions-based orchestration workflows
Collaborative cross-functional delivery lead working with Engineering, Analytics, and Operations teams; managed 2 direct reports

Production Engineer / Data Quality Analyst -- Cision Global
Oct 2018 - Feb 2022 | Austin, TX to New York, NY

Analyzed large-scale production data across PostgreSQL, Cassandra, and ElasticSearch using advanced SQL queries and Python scripts in Jupyter Notebooks
Ran and maintained Jenkins automation jobs and data integrity monitoring scripts to improve data observability across production pipelines
Ensured data compliance and improved data integrity across ingestion and procurement pipelines during GDPR; authored governance documentation
Investigated and resolved 300+ production data issues through autonomous root cause analysis and collaborative cross-team coordination


EDUCATION

B.B.A. in Management Information Systems -- Lamar University, 2018


LEADERSHIP AND COMMUNITY

Eagle Scout, Boy Scouts of America
New York Cares, Volunteer (since Nov 2025)
NYC Mesh, Community Infrastructure Support (since Nov 2025)


<!-- GENERATION NOTES

Role Structure Used: data-engineer.yaml

Skills Highlighted:
dbt Cloud (expert, 1,900+ models) — explicitly required, strongest differentiator
SQL (expert, 7yr) — core requirement
Python (advanced, 4yr, Dask/Pandas) — core requirement
Data Quality and Observability — JD defines success by this
Medallion Architecture — demonstrates modern warehousing patterns
Snowflake + Redshift — columnar warehouse experience
Pipeline Orchestration (CircleCI, Prefect, Airflow) — maps to Dagster/Airflow requirement
AI-assisted development — explicitly asked about in JD

Skills Omitted:
Zapier, Power Query (not relevant to DE role)
CRM integration details (de-emphasized, kept as data source context)
BI tooling (Looker/Sisense) — mentioned only through migration bullet
Zendesk (not relevant)
Client management framing (reframed as cross-functional collaboration)

Gap Analysis:
MINOR: Healthcare domain (JD doesn't require it; work is infrastructure-focused)
MINOR: Dagster specifically (has Airflow + CircleCI/Prefect; concepts transfer)

Confidence Score: 8/10

Cover Letter Talking Points:
1. Built data quality/engineering function from scratch at Success Academy
2. 1,900+ dbt models — expert-level, standout differentiator
3. TB-scale batch processing with Python/Dask optimization
4. Data observability and quality frameworks from zero
5. LLM coding tool usage and opinions (Cursor, ChatGPT, Claude)
6. Small team, autonomous, cross-functional collaboration

-->

---

---

# PART 3: COVER LETTER

To the Hiring Team at J2 Health,

I am writing to express my interest in the Data Engineer role at J2 Health. You're looking for someone to be the first data engineer and build the function from the ground up. That's exactly what I did at Success Academy Charter Schools. I joined a data team with no formal quality process, was promoted within months to lead the function, and built the entire data quality practice from scratch: testing standards, automated monitoring, observability workflows, and a dbt environment that grew to 1,900+ production models serving 51 schools and 18,000 users. The opportunity to bring that same foundational energy to J2 Health's data infrastructure is genuinely exciting.

My technical background aligns closely with what you've outlined. I have three years of expert-level dbt experience building test suites and maintaining documentation at scale. My Python and SQL work spans TB-scale datasets across both Snowflake and Redshift. At QuotaPath, I designed ELT pipelines integrating data from 10+ platforms into BigQuery, built data validation frameworks that cut incidents by over 50%, and migrated batch processing from row-by-row SQL to parallelized Python transformations using Dask, reducing many runtimes from hours to minutes. I work daily with Cursor, ChatGPT, and Claude, and I have strong opinions on where LLM tools accelerate development and where they need guardrails, particularly around data modeling and test generation.

While I haven't worked with healthcare data specifically, the core challenges you've described, building reliable ingestion pipelines, improving data observability, reducing time from raw data to customer impact, are exactly the problems I've solved across SaaS and education domains at TB scale. I'm also comfortable with orchestration concepts through CircleCI, Prefect, and Airflow, and I'd be eager to deepen that experience with Dagster.

I'd welcome the chance to discuss how my experience building data engineering foundations from scratch could help J2 Health scale its data infrastructure.

Best regards,


James Mayo

<!-- GENERATION NOTES

## Accomplishments Highlighted
1. Built data quality function from scratch at Success Academy — directly maps to "first DE hire" narrative
2. 1,900+ dbt models — standout technical differentiator for a dbt-required role
3. TB-scale batch processing with Dask/Pandas optimization — maps to "batch processing of large data"
4. Data validation frameworks reducing incidents 50%+ — maps to "data observability and quality"
5. ELT pipeline design into Snowflake — maps to columnar warehouse + pipeline requirements
6. LLM tool usage with specific opinions — directly requested in JD

## Gaps Addressed
- Healthcare domain: framed as transferable infrastructure skills, not a domain gap
- Dagster: acknowledged alongside existing orchestration experience, expressed eagerness to learn

## Tone Choices
- Led with "first hire" narrative because it's the single strongest positioning point
- Mentioned LLM tools proactively because the JD explicitly asks for opinions on them
- Kept healthcare gap framing brief and confident — it's minor, not worth dwelling on

## Word Count: ~340 (within 250-400 target)

-->
